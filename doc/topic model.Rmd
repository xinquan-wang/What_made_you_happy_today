---
title: "Untitled"
author: "Xinquan Wang"
date: "2/7/2019"
output: html_document
---
### Text Mining
```{r text_mining}
demo <- read.csv("/Users/wangxinquan/Desktop/2sem/STAT5243/Spring2019-Proj1-xinquan-wang/output/demographic.csv")
HM <- read.csv("/Users/wangxinquan/Desktop/2sem/STAT5243/Spring2019-Proj1-xinquan-wang/output/processed_moments.csv")
mydata <- as.data.frame(full_join(demo, HM, by = "wid"))
docs <- Corpus(VectorSource(mydata$text))
```

### Text basic processing
```{r}
#remove potentially problematic symbols
docs <-tm_map(docs,content_transformer(tolower))

#remove punctuation
docs <- tm_map(docs, removePunctuation)

#Strip digits
docs <- tm_map(docs, removeNumbers)

#remove stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))

#remove whitespace
docs <- tm_map(docs, stripWhitespace)

#Stem document
docs <- tm_map(docs,stemDocument)
```

### Topic modeling

Gengerate document-term matrices. 

```{r dtm}
dtm <- DocumentTermMatrix(docs)
dtm <- removeSparseTerms(dtm, 0.99)
#Find the sum of words in each Document
rowTotals <- apply(dtm, 1, sum) 

dtm  <- dtm[rowTotals> 0, ]
data_tp <-  mydata[rowTotals > 0, ]

```

#### Run LDA
```{r LDA}
library("topicmodels")
#Set parameters for Gibbs sampling
burnin <- 4000
iter <- 2000
thin <- 500
seed <- list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE

#Number of topics
k <- 10

#Run LDA using Gibbs sampling
ldaOut <- LDA(dtm, k, method = "Gibbs", control = list(nstart = nstart, 
                                                 seed = seed, 
                                                 best = best,
                                                 burnin = burnin, 
                                                 iter = iter, 
                                                 thin = thin))

#write out results
#docs to topics
ldaOut.topics <- as.matrix(topics(ldaOut))
table(c(1:k, ldaOut.topics))
write.csv(ldaOut.topics,file = paste("../out",k,"DocsToTopics.csv"))

#top 6 terms in each topic
ldaOut.terms <- as.matrix(terms(ldaOut,20))
write.csv(ldaOut.terms,file=paste("../out",k,"TopicsToTerms.csv"))

#probabilities associated with each topic assignment
topicProbabilities <- as.data.frame(ldaOut@gamma)
write.csv(topicProbabilities,file=paste("../out",k,"TopicProbabilities.csv"))
```

```{r}
terms.beta=ldaOut@beta
terms.beta=scale(terms.beta)
topics.terms=NULL
for(i in 1:k){
  topics.terms=rbind(topics.terms, ldaOut@terms[order(terms.beta[i,], decreasing = TRUE)[1:7]])
}
topics.terms
ldaOut.terms
```

